{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Data Wrangling Study: Tampa, FL\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Map Area\n",
    "\n",
    "Tampa, FLORIDA, USA.\n",
    "\n",
    "* https://mapzen.com/data/metro-extracts/metro/tampa_florida/\n",
    "\n",
    "I have lived in Florida for years and studied my Master and PhD degree there. I was lost in Tampa a few times so I would like to contribute to its improvement on OpenStreetMap.org."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Problems Encountered in the Map\n",
    "\n",
    "####  Since the size of the datafile is more than 300 MB, I defined _k_= 40 instead of 10 for sampling. The output sample data file is ready now.\n",
    "First, I have explored small sample datsets using k = 40 and k = 30 to investigate potential problems and solution strategies. The main probmlems were:\n",
    "\n",
    " ### 2.1.  __Gnis data__: \n",
    "The data imported from GNIS database seems to have a different format. I investigated the issue as below with a helper function:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def investigate_specific_key(filename, word, tag):\n",
    "    tag_list = []\n",
    "    for number, element in ET.iterparse(filename):\n",
    "        if element.tag == tag:\n",
    "            for item in element:\n",
    "                    item_dict = {}\n",
    "                    key = item.attrib['k']\n",
    "                    if key.startswith(word):\n",
    "                        item_dict[key] = item.attrib['v']\n",
    "                        tag_list.append(item_dict)                        \n",
    "    return tag_list\n",
    "\n",
    "investigate_specific_key(SAMPLE_FILE, 'gnis', 'node')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Gnis Data problemmatic issues:*\n",
    "\n",
    "    __1 Second level “k” tags with the value \"type\"__\n",
    "    \n",
    "     k=\"gnis:created\" v=\"10/19/1979\" \n",
    "     \n",
    "     k=\"gnis:state_id\" v=\"12\" \n",
    "     \n",
    "     k=\"gnis:county_id\" v=\"057\" \n",
    "     \n",
    "     k=\"gnis:feature_id\" v=\"293110\" \n",
    "        \n",
    "    The 'gnis' part should be assigned a new style as below:\n",
    "    \n",
    "    type = 'gnis'\n",
    "        \n",
    "    __2) 'feature_id' vs 'id'__\n",
    "    \n",
    "    From [openstreetmap wiki page](https://wiki.openstreetmap.org/wiki/USGS_GNIS), it is seen that 'id' and 'feature_id' refers feature-id. Therefore, I should convert ids to feature_id.\n",
    "    \n",
    "    \"The Feature ID uniquely identifies a feature in the GNIS database and is thus the most important thing to tag when relating an OSM feature to a GNIS feature. The tag gnis:feature_id is by far the most commonly used for this purpose. Other tags for GNIS Feature IDs include gnis:id and tiger:PLACENS.\"\n",
    "    \n",
    "    __3) 'ST_num' and 'state_id'__\n",
    "    \n",
    "    Both state_id and ST_num refers to state_id, which is 12. Therefore, I should convert ST_num to state_id.\n",
    "    \n",
    "    __4) 'county_name and 'County'__\n",
    "    \n",
    "    Both 'county_name' and 'County' refers to county_name. Therefore, I should convert County to county_name.\n",
    "\n",
    "    __5) 'County_num and county_id'__\n",
    "    \n",
    "     Both 'County_num' and 'county_id' refers to county_id. Therefore, I should convert County_num to county_id.\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2.2. __Street Names__: \n",
    "I have checked the abbreviations of the streets and made them the same format. First, I have audited them. I have used the same investigate_specific_key helper function to check the street names.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Street Names problemmatic issues:*\n",
    "***\n",
    "\n",
    "__1) Overabbreviated Street Names__\n",
    "\n",
    "  Below are some examples to the mentioned street types. All the strrets names should be more readable.\n",
    "  \n",
    " {'addr:street': '4th St N'} : '4th Street North'\n",
    " \n",
    " {'addr:street': 'S Belcher Rd'} : 'South Belcher Road'\n",
    " \n",
    " \n",
    " \n",
    "__2) Unstandardized Abbreviations__\n",
    "\n",
    "  Some street names are not over abbreviated but have unstandardized names. Those should be standardized for further analyses.\n",
    "  \n",
    "  'Boulevard' vs 'Blvd', 'South' vs 'W' (for west) and 'Avenue' vs 'Ave'\n",
    "  \n",
    " {'addr:street': 'Gulf to Bay Boulevard'} vs {'addr:street': 'Park Blvd'}\n",
    " \n",
    " {'addr:street': 'South Macdill Avenue'} vs {'addr:street': 'W Waters Ave'}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    " \n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2.3. __Postal Codes__: \n",
    "I have checked the postal codes for potential problems. Because, postal codes are critical and is a primary id for most analyses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The only problemmatic issue is unstandardized type of postcodes as below:\n",
    "   \n",
    " {'addr:postcode': '33781-5034'}\n",
    " \n",
    " I can either ignore the after-dash part or create a new key. In the sample, there exist only one this type. So, ignoring such types and deleting the after-dash part would be a beter idea.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2.3. __Housenumbers__: \n",
    "There exist suite numbers and they should be excluded and put into the unit part. An example is below:\n",
    "\n",
    "{'addr:housenumber': '2663 Suite 27'}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2.4. __Amenities__: \n",
    "\n",
    "In amenity there exist no big problem. However, some amenities are also given as keys. Examples are below:\n",
    "\n",
    " 'bicycle_parking'\n",
    " \n",
    "Those will be investigated in the additional ideas part.\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2.5. __Tiger Data__: \n",
    "\n",
    "The data imported from tiger database seems to have a different format. I investigate the issue as below with a helper function:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Tiger Data problemmatic issues:*\n",
    "\n",
    "    __Second level “k” tags with the value \"type\"__\n",
    "    \n",
    "       <tag k=\"name\" v=\"West Charter Street\" />\n",
    "       <tag k=\"highway\" v=\"residential\" />\n",
    "       <tag k=\"tiger:cfcc\" v=\"A41\" />\n",
    "       <tag k=\"tiger:county\" v=\"Hillsborough, FL\" />\n",
    "       <tag k=\"tiger:reviewed\" v=\"no\" />\n",
    "       <tag k=\"tiger:zip_left\" v=\"33602\" />\n",
    "       <tag k=\"tiger:name_base\" v=\"Charter\" />\n",
    "       <tag k=\"tiger:name_type\" v=\"St\" />\n",
    "       <tag k=\"tiger:zip_right\" v=\"33602\" />\n",
    "       <tag k=\"tiger:name_direction_prefix\" v=\"W\" />\n",
    "    \n",
    "    Tiger part should be a new 'type' key and remaining part should be other keys. The format should be as below:\n",
    "        type  = 'tiger'\n",
    "    \n",
    "    There seems no other problem in the data came from tiger database.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Cleaning and Updating Process\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below updates should be applied before preparing for database. I will write appropriate functions to clean and shape the sample data, test them and apply for the main dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.1. Gnis data updates__\n",
    "\n",
    "Second level key issues are investigated at the end. So, I  dealt with\n",
    "\n",
    "* converting ids to feature_id\n",
    "* converting ST_num to state_id\n",
    "* converting Country to country_name\n",
    "* converting Country_num to country_id\n",
    "\n",
    "I have created mappings and change_name function for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_gnis = {'gnis:id': 'gnis:feature_id', 'gnis:ST_num': 'gnis:state_id', \n",
    "            'gnis:County': 'gnis:county_name', 'gnis:County_num': 'gnis:county_id'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_name(name, mapping):\n",
    "    for key in mapping:\n",
    "        if name == key:\n",
    "            return mapping[key]\n",
    "        else:\n",
    "            return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.2. Postal Code Updates__\n",
    "\n",
    "I  only took first 5 character of postal codes.  A simple helper function was sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def postal_code_cleaner(postcode):\n",
    "    return postcode[:5]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.3. House Number Updates__\n",
    "\n",
    "I have cleared the extra part after the house_numbers. There exist exeptions that housenumbers may end with a letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def house_number_cleaner(housenumber):\n",
    "    a = housenumber.find(' ')\n",
    "    if a >=1 and len(housenumber[a:]) >1 :\n",
    "        return housenumber[:a]\n",
    "    else:\n",
    "        return housenumber.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.4. Street Name Updates__ : \n",
    "First, I have audited street names to fill the mappings for abbreviations. The functions are adopted from the Case Study Part. After auditing, I have defined the below mapping and the below function. I did not use the regular expressions, rather I have used the function from sample case to make character by character analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "street_mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Rd.\": \"Road\",\n",
    "            \"Rd\" : \"Road\",\n",
    "            \"Blvd\": \"Boulevard\",\n",
    "            \"Blvd.\": \"Boulevard\",\n",
    "            \"BLVD\": \"Boulevard\",\n",
    "            \"Cir\": \"Circle\",\n",
    "            \"Dr\" : \"Drive\",\n",
    "            \"Hwy\": \"Highway\",\n",
    "            \"Pl\": \"Plaza\",\n",
    "            \"S\": \"South\",\n",
    "            \"N\": \"North\",\n",
    "            \"N.\": \"North\",\n",
    "            \"E\" : \"East\",\n",
    "            \"S.\": \"South\",\n",
    "            \"E.\": \"East\",\n",
    "            \"W\": \"West\",\n",
    "            \"W.\": \"West\",\n",
    "            \"SE\": \"Southeast\",\n",
    "            \"NE\": \"Northeast\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update street names without using regular expressions. Adopted from sample Sql project.\n",
    "def update(name, mapping): \n",
    "    words = name.split()\n",
    "    for w in range(len(words)):\n",
    "        if words[w] in mapping:\n",
    "            if words[w].lower() not in ['suite', 'ste.', 'ste']: \n",
    "                # For example, don't update 'Suite E' to 'Suite East'\n",
    "                words[w] = mapping[words[w]]\n",
    "    name = \" \".join(words)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.5. Tiger Data Updates__ : \n",
    "\n",
    "The updates (assigning the 'tiger:' value to the 'type' attribute) will be done when I prepare the data for the database)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare the Data for DATABASE\n",
    "\n",
    "I have combined all the cleaning functions into a single clean_all function to process the data only once. And, I have cleaned the data and processed adopting the shape element functions and prepared the data for the database. All the sample data is validated and then the full osm data was processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean all the data combining all the functions\n",
    "def clean_all(element):\n",
    "    ''' Clean and update gnis keys, street names, postcodes, housenumbers using predefined functions'''\n",
    "    if element.tag == 'way' or element.tag == 'node':\n",
    "        for item in element:\n",
    "            if item.tag == 'tag':\n",
    "                key = item.attrib['k']\n",
    "                if key.startswith('gnis'):\n",
    "                    item.attrib['k'] = change_name(key, map_gnis)\n",
    "                if key =='addr:postcode':\n",
    "                    value = item.attrib['v']\n",
    "                    item.attrib['v'] = postal_code_cleaner(value)\n",
    "                if key =='addr:housenumber':\n",
    "                    value = item.attrib['v']\n",
    "                    item.attrib['v'] = house_number_cleaner(value)\n",
    "                if key == 'addr:street':\n",
    "                    value = item.attrib['v']\n",
    "                    item.attrib['v'] = update(value, street_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export the CSV Files to the Sqlite Database\n",
    "\n",
    "I have used DB-API to export the CSV files to the database. I imported 5 csv files (nodes, nodes_tags, ways, ways_tags, ways_nodes) into the SQLite database. A sample code is as below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlite_file = 'osmfile.db'\n",
    "conn = sqlite3.connect(sqlite_file)\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('''DROP TABLE IF EXISTS nodes_tags''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''CREATE TABLE nodes_tags(id INTEGER, key TEXT, value TEXT, type TEXT, FOREIGN KEY (id) REFERENCES nodes(id))''')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('nodes_tags.csv','rb') as f:\n",
    "    dr = csv.DictReader(f) # comma is default delimiter\n",
    "    to_db = [(i['id'], i['key'],i['value'].decode(\"utf-8\"), i['type']) for i in dr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.executemany(\"INSERT INTO nodes_tags(id, key, value,type) VALUES (?, ?, ?, ?);\", to_db)\n",
    "# commit the changes\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Overview of Data\n",
    "\n",
    "In this section, I have overviewed all dataset using sql queries.\n",
    "\n",
    "This section comntains \n",
    "* Size of the files\n",
    "* Number of unique users\n",
    "* Number of nodes and ways\n",
    "* Number of chosen type of nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1. File Sizes\n",
    "\n",
    "* tampa_florida.osm: .....__373.1 MB__ (The main osm file)\n",
    "* sample_tampa.osm: .....__9.4 MB__\n",
    "* tampaosm.db: .....__206.5 MB__\n",
    "* nodes.csv : .....__137.2 MB__\n",
    "* nodes_tags.csv: .....__6.7 MB__\n",
    "* ways_nodes.csv: .....__46.2 MB__\n",
    "* ways_tags.csv: .....__33.1 MB__\n",
    "* ways.csv: .....__10.8 MB__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2. Number of Nodes and Ways\n",
    "\n",
    "I have used below queries to explore the numbers as below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(sqlite_file)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Count of nodes\n",
    "cur.execute('''SELECT COUNT(*) FROM nodes''')\n",
    "rows = cur.fetchall()\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count of ways\n",
    "cur.execute(''' SELECT COUNT(*) FROM ways''')\n",
    "rows = cur.fetchall()\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below results were obtained from the above queries:\n",
    "* Number of rows: .....__1663833__\n",
    "* Number of ways: .....__184110__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3. Number of Unique Users\n",
    "The below queries were used to find unique users both in nodes and ways together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of unique users\n",
    "cur.execute('''SELECT COUNT(*) FROM (SELECT uid FROM nodes UNION SELECT uid FROM ways)''')\n",
    "rows = cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Number of total unique users: ..... __1452__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4. Number of Chosen Type of Nodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Number and type of amenities:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''SELECT value, COUNT(*) as num FROM nodes_tags WHERE key = 'amenity' GROUP BY value ORDER BY num DESC''')\n",
    "rows = cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query showed that the top numbers were as below:\n",
    "\n",
    "'restaurant': 852\n",
    " \n",
    "'place_of_worship' : 771\n",
    " \n",
    "'school' :554\n",
    " \n",
    "'fast_food' : 396\n",
    " \n",
    "'bicycle_parking' : 353\n",
    "\n",
    "There were restaurants and place of worships mostly as amenities in Tampa, FL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Number and type of keys in node_tags, way_tags:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Nodes tags\n",
    "cur.execute('''SELECT key, COUNT(*) as num FROM nodes_tags GROUP BY key ORDER BY num DESC''')\n",
    "rows = cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query showed that the most common nodes_tags keys were as below: \n",
    "    \n",
    "'highway': 25586\n",
    " \n",
    "'power', 18786\n",
    " \n",
    "'name', 18197\n",
    " \n",
    "'operator', 9607\n",
    " \n",
    "'route_ref', 9157"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ways tags\n",
    "cur.execute('''SELECT key, COUNT(*) as num FROM ways_tags GROUP BY key ORDER BY num DESC''')\n",
    "rows = cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query showed that the most common ways_tags keys were as below: \n",
    "\n",
    "'highway', 117490\n",
    " \n",
    "'name', 82528\n",
    " \n",
    "u'county', 68990\n",
    " \n",
    "u'cfcc', 68944\n",
    " \n",
    "u'name_base', 64235"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Other Ideas About the Dataset\n",
    "\n",
    "A problem I have seen in the dataset is duplication in key categories. These duplications reduces the validity of search and analysis. Moreover, the decisions made based on those data would be biased. To illustrate, below 'bicycle_parking' is assigned as a __key__. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''SELECT  key, COUNT(*) as num FROM nodes_tags WHERE key = 'bicycle_parking' GROUP BY key  ''')\n",
    "rows = cur.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query gives:\n",
    "\n",
    "(u'bicycle_parking', 45)\n",
    "\n",
    "There exist 45 bicycle_parking keys in the dataset. However, bicycle parking is also assigned as an __amenity__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''SELECT  key, value, COUNT(*) FROM nodes_tags WHERE value = \"bicycle_parking\" GROUP BY key''')\n",
    "rows = cur.fetchall()\n",
    "print rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query gives:\n",
    "\n",
    "[(u'amenity', u'bicycle_parking', 353)]\n",
    "\n",
    "There exists 353 bicycle parkings also as amenities. \n",
    "\n",
    "__We can write a script to find those duplications for further investigation.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute('''SELECT DISTINCT(key) FROM nodes_tags''')\n",
    "keys = cur.fetchall()\n",
    "\n",
    "cur.execute('''SELECT DISTINCT(value) FROM nodes_tags WHERE key = \"amenity\" ''')\n",
    "amenities = cur.fetchall()\n",
    "\n",
    "duplications = []\n",
    "for key in keys:\n",
    "    if key in amenities:\n",
    "        duplications.append(key)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The query and script gives __duplications__ :\n",
    "\n",
    " [(u'atm',),\n",
    " \n",
    " (u'fuel',),\n",
    " \n",
    " (u'social_facility',),\n",
    " \n",
    " (u'shelter',),\n",
    " \n",
    " (u'bench',),\n",
    " \n",
    " (u'bicycle_parking',),\n",
    " \n",
    " (u'waste_basket',),\n",
    " \n",
    " (u'parking',),\n",
    " \n",
    " (u'toilets',),\n",
    " \n",
    " (u'car_wash',),\n",
    " \n",
    " (u'studio',)]\n",
    " \n",
    " \n",
    "As seen, there exist several duplications to be fixed in the dataset. To fix those, we can assign them as amenities. This will increase efficiency of the search and analysis in the dataset. \n",
    "\n",
    "However, __a potential problem__ would be to transfer the other field related with those duplications such as name and value.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. References\n",
    "\n",
    "I have only used Udacity Data Wrangling Case Study and [Sample_Submission](https://gist.github.com/carlward/54ec1c91b62a5f911c42#file-sample_project-md) for this study. I have referred if I used those resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
